\documentclass{beamer}
\usepackage{graphicx}
\usepackage{amsmath}


\usetheme{m}
\title{Predicting TCP/IP Network Traffic using Time Series Forecasting}
\subtitle{Interim Presentation}
\date{May 19, 2016}
\author{Thomas Mauerhofer, and Matthias Wölbitsch}


\begin{document}
  \maketitle
  
  \begin{frame}{Recap}   
    \textbf{goal: forecast TCP/IP traffic}
    \begin{itemize}
     \item real-time and short-time
    \end{itemize}
    
    \textbf{data set}
    \begin{itemize}
     \item network traffic of three months
     \item three different resolutions
    \end{itemize}
    
    \textbf{approaches}
    \begin{itemize}
     \item classical time series prediction methods
     \item neural networks
    \end{itemize}
  \end{frame}
 
 
  \begin{frame}{Hold-Winters}
  \textbf{single exponential smoothing}
  \begin{itemize}
   \item weighted moving average
   \item \( \hat{y}_{t+1,t} = \alpha y_t + (1 - \alpha) \hat{y}_{t-1}\)
  \end{itemize}
  
  \textbf{double exponential smoothing}
  \begin{itemize}
   \item Holt's linear trend method
   \item ability to model trends in the dataset
   \item two smoothing equations (level and trend)
  \end{itemize}
  \end{frame}
  
  \begin{frame}{Hold-Winters}
  \textbf{triple exponential smoothing}
  \begin{itemize}
   \item Holt's exponential trend method
   \item ability to model trends and seasonal effects
   \item three smoothing equations
   \item two season variant of the method
  \end{itemize}
  
  
  \textbf{expectations}
  \begin{itemize}
   \item time series is highly seasonal
   \item dataset suits the method
  \end{itemize}
  \end{frame}

  
  \begin{frame}{Neural Network Approaches}
    \textbf{neural networks}
    \begin{itemize}
     \item non-linear learning
     \item flexible, powerful
     \item less well behaved
    \end{itemize}
    
    \textbf{feed-forward network}
    \begin{itemize}
     \item multilayer perceptron (MLP) network 
     \item most commonly used for forecasting
     \item sliding window over input series (i.e. set of lags)
     \item one hidden layer with \(n\) neurons
    \end{itemize}
  \end{frame}

  
  \begin{frame}{Neural Network Approaches}
    \textbf{recurrent network}
    \begin{itemize}
     \item allows cycles
     \item long short-term memory (LSTM) architecture
     \item influence of past values decays quickly → memory cells
     \item well-suited for time series forecasting
    \end{itemize}
    
    \textbf{problems and expectations}
    \begin{itemize}
     \item LSTM is not straightforward
     \item LSTM should outperform MLP
    \end{itemize}
  \end{frame}

  
  \begin{frame}{Evaluation}
    \textbf{accuracy measures}
    \begin{itemize}
     \item sum squared error (SSE)
     \item symmetric mean absolute percentage error (sMAPE)
     \item \ldots
    \end{itemize}
   
    \textbf{scaled errors}
    \begin{itemize}
     \item compare forecasts on series of different scales 
     \item mean absolute scaled error (MASE)
     \item compare forecast with naïve method 
     \item seasonal version: \(\hat{y}_{t+h,t} = y_{t+h-K}\) %
    \end{itemize}
  \end{frame}

  
  \plain{Questions?}
  
\end{document}